[3s] Okay. Hello everyone. Um welcome to our
[5s] second lecture um in the ongoing um uh
[10s] double operatic theory of systems uh
[13s] lecture series. Um we're not yet to
[17s] double operads. We're still on
[19s] categories. So let me review a bit of
[22s] what we did last time. And this time
[24s] we're just going to see um I believe
[26s] more more categories of systems and more
[29s] notions uh more features of systems that
[32s] are representable by maps between
[34s] systems. So last time we saw two
[39s] categories of systems. So last time we
[41s] saw so one
[44s] we saw uh discrete time
[48s] time discrete space
[52s] space uh dynamical systems. Wow,
[58s] that's a long phrase for just a single
[62s] function U from S to S uh in the
[66s] category of sets
[73s] um where a map here.
[76s] So a map
[78s] uh and a map here
[82s] is uh a function f from s1 to s2 such
[87s] that the square commutes. So s1
[92s] um u sub1
[96s] s2
[98s] u1 u2 sub2
[102s] ff
[104s] commutes i.e.
[106s] For all s in s1 we have that f of u1 s
[114s] equals u2 f of s. Okay. And we saw how
[120s] um uh sequences of uh states that update
[124s] according to this law were given by maps
[127s] out of uh out of the natural numbers um
[130s] ticking forward. So we have a uh here we
[132s] have a clock
[135s] a clock
[137s] which is uh n and then we add one to n
[144s] and uh maps
[148s] so I'll call this clock
[151s] maps from the clock
[155s] to s
[157s] uh are sequences is
[165s] in s uh such that um s uh m +1
[172s] is equal to u of sn. So they update
[178s] according to this and therefore they're
[180s] determined by excuse me therefore
[182s] they're determined by s0.
[185s] Okay. So um I will call like one one
[189s] thing we could call this is we could
[191s] call this category set to the um loop
[196s] because we uh think of this as a as a it
[200s] could be thought of as a the category of
[202s] functors from the category freely
[204s] generated by a single loop into set. Um
[209s] and uh and so if we wanted to, we didn't
[213s] talk about it last time, but if we
[214s] wanted to have other kinds of discrete
[216s] time things, we could we could look at
[218s] other categories. So we could replace
[221s] for example set to the loop.
[224s] So this is discrete space
[228s] and this is all discrete time.
[234s] But then we could also if we wanted
[235s] continuous space right we could use
[239s] topological spaces and look at a loop
[241s] and that's the same it has the same sort
[243s] of category here but instead of sets it
[246s] would be so instead of this one here
[249s] instead of sets it would be topological
[252s] spaces
[256s] and then this map would have to be
[259s] continuous
[262s] and it's perhaps much more common to see
[264s] also um measurable spaces.
[268s] So this would be continuous space
[272s] is continuous dynamics
[276s] and this one here is measurable space
[280s] measurable dynamics
[284s] which is the the the most common one
[287s] you'll you'll see in practice but we can
[289s] also do in other categories and so I
[292s] think I'll try and get to other
[293s] interesting categories like um uh A
[298s] we'll see some other interesting
[300s] interesting categories here in discrete
[302s] time like partial maps
[306s] uh which gives us non-determinism
[312s] and uh marov
[315s] uh kernels
[317s] which gives us stoasticity
[321s] see so we we'll I I'll try and come to
[324s] those uh later today. So we also saw
[328s] continuous time.
[333s] We saw continuous time
[337s] time uh in the form of ODE.
[340s] ODE
[342s] and we saw that ODEs can be represented
[344s] as vector fields. So um ODEs as vector
[349s] fields
[350s] fields.
[352s] So um an OD is an ordinary differential
[355s] equation. Okay. So a vector field is we
[358s] have some kind of manifold S um which
[361s] you could think of as being Rn and uh we
[364s] have its tangent bundle pi uh uh ts and
[368s] the tangent bundle is roughly speaking
[372s] pairs of a point uh s and s paired with
[377s] the tangent space at that point
[381s] like this. And these are the sort of
[383s] infinite decimal
[386s] changes
[388s] to S. They're the infinite decimal
[391s] changes you can make in the state. Um
[394s] and so a a section here u is a vector
[399s] field. So this such that pi u equals in
[404s] s. In other words, we have U of S is
[408s] sort of is in T SS. In other words, in
[412s] this time, instead of saying what the
[414s] next state will be, we say in our
[417s] dynamics, we say how to make an infinite
[419s] decimal change in the current state.
[423s] Um, and a solution.
[425s] So a solution
[430s] of u is uh is an actual function of
[434s] time.
[438s] Uh so in fact I might write it by I
[442s] might bind a variable in r just to tell
[445s] you this is a function of time.
[449s] So it's a function of time uh such that
[452s] the derivative of s with respect to time
[456s] is equal to u of s of t
[464s] or and then we also saw that this as
[467s] well can be expressed as a map of odes
[474s] where this is the constant one vector
[477s] field. So the unit time this sort of
[480s] represents the OD dt dt = 1
[486s] and then here is s and here's s here is
[491s] t s
[493s] then this is t of little s
[498s] um and that is the uh push forward of
[502s] vectors
[507s] which is given by taking the directional
[509s] derivative
[515s] or just the derivative in this case
[517s] because the um
[520s] the domain is r.
[522s] there's one direction. Um, and what we
[526s] what we need to commute is these uh the
[528s] bottom the the the sort of squares that
[530s] go down the square that goes downward
[531s] always commutes and what we need to
[532s] commute is the other one i.e. we want ts
[536s] of one
[538s] uh to equal u of s and ts of one is
[543s] precisely the push forward. So this is
[545s] actually just the SDT and there we have
[548s] our um
[550s] came from up top. Okay. So uh I want to
[555s] talk about a few more kinds of systems
[557s] today. I also want to talk about a few
[559s] more kinds of representations. So one so
[563s] um so let's see some more representable
[565s] notions of the systems we've already
[567s] had.
[573s] So uh one is steady states.
[579s] So uh so in let's do the discrete time
[586s] right. So uh s in s is steady
[591s] for u
[594s] when
[596s] u of s equals s.
[599s] Very nice. So now,
[603s] as we mentioned last time, you can
[605s] represent elements of sets by maps from
[608s] a single element set. So this is a is a
[610s] map from a single element set with a
[612s] single dummy element to S,
[616s] right? It just picks out that it sends
[618s] that dummy element to the elements we
[620s] need. So I'm just going to I'm going to
[621s] always identify elements with maps from
[624s] this terminal set. And so uh right
[629s] that's just what that means. So in in in
[630s] in other words we have here a map like
[636s] this
[637s] we have uh u and then you can see that
[640s] this equation expresses a sort of
[642s] commutivity. If I put here
[646s] another copy of s and here I put the
[648s] identity
[650s] which is the only map that I could put
[651s] there.
[653s] um that this equation here becomes this
[656s] commutive square and this is a map from
[659s] from uh this thing here
[665s] as a single object to you as a dynamical
[669s] system. So in other words, steady states
[675s] are representable
[679s] by well what is this system here that
[682s] represents steady states? Well, it is in
[684s] a sense the system that only has exactly
[686s] one steady state because you see it has
[688s] a single state namely star and that
[690s] state updates to itself. So this is you
[694s] know by the by the if we will steady
[697s] state
[699s] and it's just like how um
[704s] it's just how uh like uh uh trajectories
[707s] are representable by the trajectory the
[710s] the system that just has a single
[713s] trajectory updating which is which is
[716s] sort of a clock. So we saw that that um
[719s] maybe I should say here this thing here
[722s] which expresses the the the OD
[726s] um dddt equals 1 is acts as our sort of
[729s] clock for ODEs.
[732s] Okay.
[734s] So
[737s] excuse me. Okay. And also so that's in
[741s] discrete time
[743s] but in uh continuous time
[749s] we can also do that. So s is a steady
[751s] state
[753s] is steady
[755s] for u but now u is a section of the
[758s] tangent bundle
[760s] when well us
[763s] is now not the next state it's how the
[766s] state is changing. So if we want the
[768s] state not to change, we need it to be
[770s] zero. Um zero is the uh the tangent
[774s] vector that says you don't change,
[776s] right? And that again is also
[778s] representable because here we can put t
[783s] star
[784s] and star here
[787s] to s. Now I'll note that this is a
[789s] manifold. It is r0,
[792s] right? It's r to the zero. It's the we
[795s] might call that element the single point
[797s] zero if we want instead of star
[800s] here.
[804s] Um here's s right
[808s] and here is u this is and here right
[812s] well we're going to put this here the
[814s] tangent bundle of r0 is r is is also r0.
[819s] But this is in fact uh going to be
[821s] roughly speaking the identity because
[823s] this is isomeorphic to just star again
[826s] or maybe I should say zero here. Um
[830s] because of that this picks out a single
[832s] element and it's the derivative of this
[834s] function s that function is constant. It
[838s] it can't vary. It has no domain over
[841s] which to vary. So this is actually
[844s] picking out zero. And so again we see
[847s] that this this uh commutation here
[850s] expresses this equation.
[854s] So steady states are representable by
[855s] again the steady state. It's a system
[858s] with exactly one one state and its
[861s] dynamics. This this thing represents the
[864s] equation uh d uh uh you know d or you
[869s] know if it will d
[872s] there's no variable here. So it's a dxdt
[875s] or dtdt equals z where but also
[880s] so t equals z. I don't know exactly how
[883s] to say this. There's only one state in
[885s] here. It can't change. Okay. So steady
[888s] states. Another thing we can talk about
[889s] are periodic orbits.
[897s] Right? So in discrete time
[901s] we might have a state here.
[904s] So s in s is periodic
[910s] uh
[914s] uh when
[917s] you know for you when u to the n
[921s] of s is equal to s for some n
[926s] some period
[929s] n. So in other words uh it's it's
[934s] a state is periodic when it eventually
[936s] comes back to itself but it doesn't have
[938s] to do so uh on the next step. Um usually
[942s] the period is defined to be the the
[943s] smallest such n
[946s] uh and again this is representable where
[948s] now we're going to take the set.
[952s] So now right we actually have uh quite a
[955s] this this equation here refers to
[958s] something that's a little bit further in
[959s] time right so there's sort of a bunch of
[961s] intermediate values that aren't
[963s] mentioned here which is to say there is
[967s] uh s there's u of s there's u ^2 of s
[970s] there's u cubed of s all the way to u n
[975s] of s and that's the one that equals s.
[978s] So in fact these many things right of
[981s] which there are n
[984s] um these many things we need to sort of
[987s] uh name in our represent. And so our
[990s] representer here will be 0 uh 1 2 dot
[993s] dot dot n minus one
[997s] which is often referred to as brackets
[1000s] n.
[1002s] Um
[1004s] and uh and as we see you know this
[1007s] sequence here
[1010s] I'll just call s will if I define um uh
[1015s] or like I guess I should say it's u
[1017s] blank of s like that
[1021s] to um uh uh s and then here is u and
[1027s] then we need this again. So here's
[1028s] brackets n just make it it's the same
[1031s] set. Um and then here we're going to
[1034s] take u blank of s and now we want to put
[1037s] something here so that this commutivity
[1040s] expresses that and what we'll do is plus
[1042s] one but now we need something special
[1046s] because uh it's certainly true that in
[1048s] this sequence right u n ui of s uh u of
[1054s] ui of s is ui + 1 of s that's by
[1058s] definition so that's perfectly fine but
[1061s] then when we get to u n we want that u n
[1064s] of s to equal u0 of s which is just s.
[1068s] Um and so we're just take it mod n. So
[1072s] there you go shifting up mod n. Okay. Uh
[1077s] and so that gives us so in other words
[1079s] periodic orbits also representable also
[1082s] representable.
[1084s] And and if you if you note this thing
[1087s] again is just the periodic or this is a
[1090s] it has a single state zero which is
[1092s] periodic because uh if I hit hit with
[1095s] plus one mod end n times I get back to
[1099s] zero and no no less. So this is a true
[1101s] period and that that's the smallest end
[1103s] which it is. then this is um uh uh
[1110s] this is um uh uh the the system that
[1113s] just has a periodic point,
[1116s] right? Um and what what's kind of fun is
[1118s] by by looking at uh sort of quotients of
[1121s] systems, so maps of systems um that are
[1125s] are sortive here, we can see that we're
[1127s] going to get the sort of divisible the
[1129s] parts of the the the smaller part
[1131s] periods that we could get here. And so
[1134s] there's a sense in which like nothing
[1135s] about this said that n was minimal. Um
[1138s] nothing about having a map like this
[1140s] said that n was minimal. But if we sort
[1142s] of take the the the image it will factor
[1145s] through something that will be uh that
[1148s] will be minimal.
[1152s] We can also do continuous time.
[1157s] So s is periodic. Well, now s has to be
[1160s] a time varying uh function of states is
[1166s] periodic
[1168s] when s of t + n is equal to s of t for
[1175s] all t for all t.
[1178s] Right? And so uh you can see that this
[1182s] it has to be a trajectory um this should
[1185s] say solution
[1187s] of you know ds
[1190s] equal us
[1192s] there has to be a solution which as we
[1195s] saw was already representable. Um but
[1197s] now just as here we took n modded out by
[1202s] n or you know if you will plus n here we
[1207s] can take r modded out by plus n and
[1210s] that's equal to the circle or
[1213s] isomeorphic to a circle.
[1218s] And so uh uh so how does that work?
[1221s] Well, um the actual uh quotient function
[1226s] there is um
[1230s] usually given by the uh an exponential
[1234s] if we wanted to put it in the the circle
[1236s] on the actual plane.
[1239s] Um but uh we can arrange this uh arrange
[1244s] this uh well enough. So if you basically
[1247s] if you have a map if you have a map from
[1249s] the circle here which by the way is um
[1252s] you know
[1260s] I'll say one but it's the radius if you
[1263s] will the radius sort of depends on m
[1267s] uh in a way that I haven't prepped for
[1269s] and we'll make a mistake
[1273s] and
[1274s] on pie
[1276s] uh the yeah the the relationship between
[1280s] n and the radius will depend on pi and n
[1285s] um right so if a circle goes to s right
[1290s] this is the function s now it looks like
[1293s] it's a function of two variables but we
[1296s] we want to think of it as also uh we
[1299s] could think of it instead as a function
[1300s] of the angle
[1302s] so we could think of it as a function of
[1304s] of uh the angle
[1309s] um cossine theta sin theta
[1314s] um for theta and r.
[1318s] And thinking about it that way now, we
[1320s] see that it's it's really they they're
[1322s] they're they can be expressed as a
[1323s] function of one variable, and that's the
[1325s] one we're doing. And I'm definitely
[1327s] going to mess up the actual relationship
[1329s] between this and n. But um n doesn't
[1332s] even have to be a in this case doesn't
[1335s] have to be a natural number. It could be
[1337s] a real number.
[1341s] Okay?
[1343s] Um, and the the actual tangent vector
[1345s] here, if you think of the circle like
[1347s] this, the tangent vector is going to be
[1350s] the one that you would get like this.
[1354s] Sort of the
[1356s] canonical flow. I'm going to add a few
[1358s] more.
[1360s] Um, it's the canonical flow around
[1365s] the circle.
[1367s] Um,
[1369s] okay.
[1372s] Okay, so we've seen a number of
[1374s] different little uh quantities that are
[1376s] representable by maps into dynamical
[1379s] systems. Um now let's talk a little bit
[1381s] more about other map other kinds of
[1383s] dynamical systems um and uh and um
[1389s] other sorts of representable
[1391s] uh things we can do with them. So okay
[1395s] so more systems.
[1400s] So one
[1402s] uh labeled
[1405s] transition systems.
[1411s] These are uh labeled transition systems.
[1414s] This is an attitude
[1417s] an attitude
[1421s] towards labeled graphs
[1426s] graphs. So by a graph I'll always mean a
[1430s] category theorist graph. So a graph
[1436s] is a directed multigraph.
[1443s] So it has a set of edges
[1448s] um eg and a set of nodes ng and then two
[1453s] functions like this which we'll call
[1455s] source and target.
[1458s] And so this is the set of edges.
[1462s] This is the set of nodes.
[1464s] and and every edge here e goes from se
[1469s] to te
[1472s] like that.
[1475s] And so uh just as an example of this,
[1480s] if if we wanted to write the graph here
[1483s] that was like uh a b c and it had an
[1488s] edge there, an edge there and a loop
[1490s] here cuz I can have a loop. Um and it's
[1493s] allowed to have an edge going back. So
[1495s] now I have to label all these 1 2 3 4.
[1499s] Right? Then down here for N, NG is going
[1503s] to equal the set
[1505s] uh A B C. EG is going to equal the set 1
[1511s] 2 3 4.
[1514s] And the maps uh that go down um are
[1518s] going to express the relationship. So
[1520s] for example one is going to go to a
[1523s] under s and it's go uh under t and it's
[1527s] going to go to b under s and uh
[1531s] similarly for all the other uh relation.
[1535s] Okay. So now a so uh a graph
[1538s] homomorphism
[1545s] uh is a natural transformation
[1551s] formation of this data.
[1556s] And what that means is uh phi from g to
[1559s] h consists of
[1563s] maps of both the underlying datas.
[1568s] Here
[1572s] really call this EI or maybe FI E
[1582s] by N
[1584s] and then so that both the squares
[1586s] commute here
[1590s] T both those squares commute and so what
[1594s] does that mean? I.e. We we have if we
[1597s] have an edge E from A to B in G, we get
[1602s] a map from 5 N A to F N B
[1610s] 5 E E and I usually am going to suppress
[1613s] the subscripts and just write all of
[1614s] these things as five.
[1618s] So a map of graphs preserves uh source
[1621s] and target.
[1623s] Um okay so now uh an example so an edge
[1627s] labeling so an edge labeling
[1633s] thing of a graph
[1638s] g is a function
[1641s] eg
[1645s] uh l to some set of labels
[1655s] We usually pick the labels in advance.
[1656s] So I would say in L.
[1660s] Um okay. So uh we can actually express
[1663s] this. So equivalently
[1668s] an edge labeling
[1672s] is a homorphism
[1676s] from G I'll also call it L to this graph
[1679s] called BL where BL is equal to L
[1686s] as edges and a single node which we call
[1690s] star
[1692s] here and well there's only one function
[1695s] you can take from any set into that set
[1697s] with a single element. You got to send
[1698s] everything to that single element. So in
[1700s] other words, this is the graph here
[1702s] whose uh uh whose which has one object
[1707s] star and um all the elements of L are
[1712s] considered as loops.
[1714s] So if you think of that homorphism
[1717s] geometrically speaking sort of it takes
[1718s] all the points of G and it crushes it
[1720s] into a single point. you're left with a
[1722s] bunch of loops and you map those into
[1725s] each of these labels. Right? So now with
[1728s] that point of view, it's quite nice
[1730s] because now we can say so a map of of
[1733s] labeled graphs
[1735s] uh labeled graphs
[1738s] is a trianguting triangle or commuting
[1742s] square. Let's say
[1745s] G to H
[1747s] B L
[1750s] B L like this um where this is LG and
[1755s] this is LH this is fi in other words a
[1759s] map is simply
[1761s] so if we write this out the labeling
[1764s] LH of PH of E is equal to LG of E. In
[1772s] other words, a homorphism of of labeled
[1775s] graphs is a graph that um
[1780s] is a graph homorphism that preserves the
[1783s] labelings. Cool. So now that's a bunch
[1787s] of uh stuff like that. So what's a a
[1789s] label transition system? a labeled
[1792s] transition system
[1797s] for a labeling set
[1801s] set L is a graph
[1804s] labeled in L.
[1810s] So um uh uh we we think of the labels
[1814s] here as actions. So this is equal to a
[1818s] set of actions
[1821s] and the idea is that the uh nodes of the
[1825s] uh of the of the graph. So if we have
[1829s] for example G to BL LG.
[1834s] So the nodes of the graph G are thought
[1837s] of as states and the edges are thought
[1839s] of as these transitions, ways that you
[1841s] can change between states. and they're
[1843s] labeled by the action you would have to
[1845s] take to do that transition. So thought
[1847s] of as dynamical systems, these are
[1849s] discrete time non-deterministic systems
[1853s] because there's nothing here that says
[1855s] that there's a unique edge out with a
[1857s] given label.
[1860s] Okay. So now
[1862s] with that idea
[1865s] um with that idea
[1868s] what is sort of a behavior
[1875s] of these sometimes known as a trace of
[1878s] these LTS's.
[1882s] Well, it's going to be a sequence. So
[1885s] given a sequence of labels or or given a
[1889s] sequence of actions. So given a sequence
[1893s] a1 dot dot a n of actions
[1899s] uh in l
[1902s] right.
[1904s] We can define a trace.
[1906s] A trace for
[1908s] uh for this sequence
[1911s] is a sequence
[1914s] of edges
[1918s] uh
[1921s] uh let's say E1 dot dot en
[1925s] uh such that
[1928s] you know when we took the action
[1931s] uh
[1933s] it had that you know they they had the
[1935s] correct label. So we're taking that
[1936s] action on the edge and we have that
[1938s] correct label.
[1940s] Um
[1943s] uh and they have to line up. So these uh
[1946s] uh and they they line up
[1950s] up which means that the target of EI is
[1953s] equal to the source of EI + one. So in
[1957s] other words we have some kind of graph
[1958s] here like a B c or
[1962s] eight some
[1965s] X dot dot doty
[1970s] maybe some other dots here.
[1977s] So uh by the way um sometimes label
[1980s] transition systems are called flowcharts
[1982s] which is a much nicer name for them but
[1985s] um and here is so a uh so I'll call this
[1991s] like one
[1994s] one two one one
[1998s] uh two one one one two
[2003s] and uh so for for this example L is
[2006s] equal to just one two.
[2010s] And so um you can see if I take my
[2014s] sequence here to be 1111
[2021s] uh 1112 let's say
[2025s] that will give me a that and then a
[2027s] possible edge set for that sequence
[2030s] would be one one one
[2033s] two
[2035s] like that. So that would be a trace. But
[2038s] um if I take it to be uh instead if I
[2042s] did um I go back.
[2050s] If instead I did uh
[2054s] I did two 11 one2
[2059s] 2112
[2061s] then I actually have multiple different
[2063s] traces for this. So I I have to take
[2065s] this two. But then I could have multiple
[2067s] different traces. I could go this way
[2069s] and then this way and then this way or
[2071s] or I could go, you know, this way,
[2076s] this way, this way and then this way.
[2079s] And so as you can see the the the
[2080s] behaviors here are sort of
[2082s] non-deterministic, but these are
[2083s] examples of traces. So maybe you can see
[2086s] what is going to represent this. If I
[2088s] put here n by which I mean the graph now
[2093s] which has which looks like this
[2106s] that
[2109s] and I label it using a
[2115s] in other words I label the the edge
[2118s] AI with the act the se the action AI,
[2123s] right? Then a morphism like this here to
[2127s] here. Well, it's going to send each one
[2130s] of these edges up top to an edge in G
[2133s] and they have to end up because
[2135s] morphisms preserve source and target.
[2137s] They have to line up. So as you can see
[2141s] uh the the the traces of one of these
[2144s] label transition systems are
[2147s] representable in these ways and uh you
[2149s] know these can be used for lots of
[2150s] different things but often you you you
[2153s] might want to say that you have a source
[2154s] node and a sync node and these have to
[2156s] start there and if you added that data
[2158s] you can still have this this represent
[2160s] in that way by say um uh marking certain
[2165s] data here. So the general ideas of
[2168s] category theory, let me maybe say that
[2170s] how that works. Let's say I wanted to do
[2171s] a source and target here.
[2175s] Going to move this whole thing down.
[2178s] Let's say I wanted to also mark a source
[2180s] and target. Well, that's extra data that
[2183s] I have to put. So I should put that in
[2185s] my definition of system. So if I had a
[2188s] source and target node, right? Like um a
[2192s] source
[2195s] target
[2196s] I could represent that as a homorphism
[2198s] into my graph G from from the the graph
[2202s] that just has two distinct nodes source
[2203s] and target. Right? But now you see that
[2207s] my my diagram is looking a little
[2208s] awkward because I really should take my
[2210s] morphisms to be natural transformations
[2212s] of the data of each object. So I really
[2214s] should put some kind of source and
[2216s] target here
[2218s] which is clearly going to be zero and n.
[2222s] Um,
[2226s] right. And now I need it to be a natural
[2228s] transformation. So I need this to to
[2230s] work here. These are actually going to
[2231s] be the same here. So maybe I should say
[2233s] that this is um
[2236s] these are equal. This is source. This is
[2239s] target and this is source maps to zero
[2243s] and target maps to n. Right? Or a source
[2247s] in sync is procrastination.
[2250s] Now when this commutes this also says
[2252s] that in fact
[2254s] they have to go so maybe this is x and y
[2257s] here in our graph over on the right. Now
[2261s] when they now for that top square to
[2263s] commute means that zero has to go to x
[2265s] and y has to go to to uh uh uh and and n
[2269s] has to go to y because those are the
[2270s] source and sync of of g. And so you can
[2273s] see the general idea of of of uh in
[2277s] category theory is sort of you derive
[2278s] the notion of of the correct notion of
[2280s] morphism from the definition of your
[2283s] objects. And if you want to add extra
[2285s] data into your notion of system, you
[2288s] should keep track of it in your notion
[2289s] of morphism. But when you do, you find
[2291s] that if your ex if your notion of
[2294s] behavior required understanding that
[2296s] extra data like a source in sync, right?
[2299s] So now you only want traces that go from
[2301s] source to sync then it will still appear
[2304s] in the map. The extra conditions you
[2306s] need will appear in these sort of maps
[2308s] between them. That's sort of a takeaway.
[2311s] Okay.
[2312s] So we have label transition systems. Um
[2316s] at some point these lectures are going
[2318s] to start rapidly increasing categorical
[2320s] sophistication but I think we're going
[2322s] to save it up for one more.
[2326s] And I'm going to talk about um
[2327s] nondeterministic. So let's talk about
[2330s] now
[2331s] discrete time
[2334s] non-deterministic systems.
[2345s] So uh the simplest kind so the simplest
[2350s] most kind of non-determinism is where we
[2353s] don't know exactly what the next state
[2355s] will be but we know a set so is is um
[2359s] non-determinism
[2362s] uh of non-determinism is going to be
[2365s] possibilism.
[2369s] So we say from U it takes a state not to
[2374s] a next state as in uh as in um
[2378s] determinism but it takes it to a set of
[2381s] states. So this here is the power set
[2385s] i.e. set of subsets.
[2390s] So now right
[2392s] now we that's a that's a reasonable
[2394s] notion of of uh of system and a morphism
[2401s] here would be something like this s to
[2404s] ps
[2407s] well maybe I'll leave it off and we'll
[2409s] do other the notion of morphism here is
[2412s] a little like uh not doesn't follow the
[2415s] scheme exactly in my opinion
[2417s] so we'll we'll come back to written bit.
[2421s] The the next is stochcastic
[2425s] and here what we want to say is that U
[2428s] of S. So U of S here is a subset of S.
[2431s] This one iterate. So U of S now we want
[2435s] is a probability distribution. It's a
[2438s] conditional
[2441s] conditional
[2444s] probability distribution.
[2449s] on states. So U of S normally this would
[2454s] be written P
[2456s] given S where P stands for probability
[2459s] but really you have to actually say what
[2462s] distribution you're drawing that
[2463s] probability from. So that should be said
[2465s] somewhere.
[2466s] And so we would maybe we would say as u
[2469s] of s u of s could be this but we should
[2471s] say u of s is equal is a probability
[2475s] distribution that looks like this
[2480s] uh on s.
[2482s] So we can think of u now as a function
[2487s] to the set of probability distributions.
[2492s] This often denoted as delta.
[2496s] So this is the set of probability
[2499s] distributions.
[2503s] And I will note that in in so right now
[2505s] we have both of these have a similar
[2508s] form or I might do a few other ones.
[2511s] there's also just like potential to halt
[2513s] halting.
[2516s] So this is nondeterministic in the in
[2518s] the sort of simple sense that it is
[2521s] deterministic really but um a uh a state
[2525s] might go on or it might stop. So we
[2528s] might say that here we have u s goes to
[2531s] s disjoint union bot where here we uh
[2536s] call this the halting state halting and
[2540s] it's it's uh it's not instead of
[2543s] considering the halting state to be a
[2544s] separate state of its own we are going
[2547s] to consider it to be an extra state that
[2549s] sort of gets added on at the end. The
[2551s] reason is that the halting state is
[2553s] supposed to be where your system just
[2554s] stops. So there's no reason to define a
[2556s] dynamics for it.
[2558s] If you want, you can always extend this
[2561s] to a function that just you sends botto.
[2565s] But I think keeping it this way shows
[2567s] that there's sort of this pattern here
[2570s] thing here. This is sometimes known as
[2573s] maybe
[2575s] in the computer science literature.
[2578s] um by definition. Um in other words, U
[2582s] here is a function that takes in a state
[2584s] and will give us well it will maybe give
[2586s] us a state a next state or it will halt.
[2592s] And so in general
[2596s] in general
[2598s] we have a monad
[2602s] a well I guess it really doesn't need to
[2604s] be a monad. I'll just say an endopun a
[2607s] puncture
[2612s] f. I don't know why my f got so fancy.
[2617s] I have to save my fancy letters for a a
[2619s] serious climb up the category dimension
[2621s] ladder. That's going to happen
[2625s] uh from set to set.
[2629s] Um and so uh this funer like that sort
[2633s] of describes
[2638s] power nondeterminism.
[2643s] Okay, I'll do it this way. Right, so we
[2646s] have s to f of s
[2650s] u is an fn nondeterministic
[2659s] system.
[2660s] So we have in in case one we had f equal
[2663s] power set.
[2666s] In case two we had f equals delta uh
[2670s] probability distributions.
[2673s] In three
[2675s] we had it being the maybe monad as it's
[2678s] called. Maybe we add an extra thing. But
[2680s] there's so many else other things we
[2682s] could do. we could uh we'll see a number
[2685s] of of we'll see more of these as we as
[2688s] we talk about systems that can actually
[2690s] couple with each other which we're going
[2692s] to I think at this rate come to next
[2693s] time.
[2695s] Um
[2697s] uh and of course we don't actually have
[2698s] to be from set to set. We could be from
[2701s] any category to any category because of
[2703s] course this uh this formulation here
[2707s] works in any category in Z.
[2712s] So the correct the obvious notion of
[2714s] morphism as a as a uh uh you know
[2717s] category theorist would say is going to
[2720s] be like this.
[2734s] Oh and I should say this zero here is f
[2738s] equals the identity functor is
[2740s] determinism.
[2744s] If f is the identity functor which is to
[2747s] say it just takes s to s then it just
[2749s] sort of disappears in all these formulas
[2750s] and we get back to where we were. Okay.
[2754s] So that this here says uh a number of
[2757s] things in all these cases but we have to
[2759s] understand how a funer acts on these on
[2761s] these morphisms right so in this case
[2764s] right in this top one here a
[2767s] homamorphism maybe I'll do the
[2770s] homes
[2773s] in one here a home would be something
[2776s] where as you can see it would say that
[2779s] uh uh the you have to understand how the
[2781s] power set is functoral and it's going to
[2783s] be funal by taking the direct image.
[2786s] Right? So this would say that um f uh u
[2790s] sorry
[2793s] where's my eraser here
[2796s] that u2 of f of s is equal to f maybe
[2802s] I'll put lower star and say that it's a
[2804s] direct image of u1 of s. Um that's
[2808s] actually a rather strong condition. It's
[2810s] a rather strong condition because what
[2813s] that says is that um uh for example if
[2817s] we tried to do our trick about
[2818s] representing trajectories this would
[2820s] have to say that actually um if we if we
[2824s] tried to do for example in this case
[2826s] right it would be U2 of say n +1 in our
[2829s] plus one trick here would be well uh it
[2833s] would be the u1 is uh uh sorry uh sorry
[2838s] u1 of
[2840s] That's right. If we tried to do this
[2843s] where S1 here down here was maybe like
[2847s] N2
[2850s] uh well
[2855s] + one. A lot of these uh functors, all
[2857s] of these functors have a case of direct
[2859s] delta or singleton inclusion uh or unit
[2864s] as it's often called that would let us
[2866s] promote a um a system into the other
[2870s] kind. Um so this would be S1 here
[2878s] SN and the other kind here. Well, u1 of
[2882s] s n is sn plus one and then we have this
[2885s] f lower lower star here. So it's just f
[2888s] well now it's just really a singleton at
[2891s] f of of sn + one. Um and that is rather
[2897s] strong that says that actually the the
[2899s] sequence so the clock for
[2901s] non-deterministics with this kind of
[2904s] morphism
[2905s] only gives you um uh behaviors that do
[2909s] update deterministically. So you're
[2910s] losing a lot, right? Um for the
[2913s] stochcastic one it turns out that you
[2915s] can actually get um uh the correct
[2918s] notion of of uh behaviors updating
[2922s] according to law where now we take the
[2925s] push forward of distributions
[2927s] which is given by sort of the uh uh
[2932s] so maybe I I don't know if I how much I
[2934s] want to go into this but the the actual
[2936s] formula for the inverse image right is
[2939s] the set of all um or maybe I'll do it.
[2943s] Yeah, it's the set of all um S2
[2948s] such that there exists an S1
[2952s] uh in U1 S
[2956s] and
[2959s] and F of S1
[2963s] equals S2.
[2966s] And the push forward of distributions
[2972s] is equal to the integral
[2976s] over all um
[2979s] uh
[2982s] uh s1
[2985s] such that
[2987s] uh f of s f f of s1 equals s2
[2991s] valued s2
[2994s] of the
[2998s] u uh of the probability
[3001s] Um, oh man,
[3004s] I can't do this off the top of my head.
[3006s] I'm sorry.
[3008s] The danger of not prepping any of these
[3009s] lectures. Um,
[3012s] maybe we could pause and I could look it
[3014s] up,
[3020s] right? Um
[3025s] we're doing here things over set. So I'm
[3028s] going to avoid any um measure stuff.
[3031s] It's in fact a little easier to write
[3032s] the formula with um the measures
[3036s] involved. But um
[3040s] be f inverse. So it will be uh s
[3047s] we have to know what uh what pushing
[3049s] forward a distribution even looks like.
[3054s] Uh so sorry
[3057s] we're going to define the the we're
[3059s] defining these on sets so we can define
[3060s] them on their elements rather than on
[3064s] some element here in S2.
[3071s] of
[3073s] u1 s.
[3078s] So this is the sum over the inverse
[3080s] image of the value of the thing and this
[3082s] is very similar to this exists over the
[3086s] inverse image of uh of the of the truth
[3090s] of a predicate.
[3092s] Um so that is uh where that
[3099s] happens. And then here um here uh f star
[3104s] u1 of s is just equal to well there's
[3107s] two cases f of s or bought uh depending
[3111s] on whether or not um uh u1 of s was
[3117s] bought or not. Um okay so in in this
[3121s] case uh what we see in this case again
[3124s] the the notion of transformation down
[3126s] here would be very strong
[3129s] um uh uh but it turns out that you can
[3133s] actually get a good notion of
[3134s] representable behavior but I'm going to
[3136s] have to leave that for another lecture
[3138s] and which I will which I will cover
[3139s] because I think it's quite cool um uh
[3143s] and you can't quite do it over the
[3145s] category of sets so well it's really a
[3147s] point where you have to use start to use
[3149s] measure theory and really do probability
[3151s] theory. Um but in the maybe case what
[3154s] you see is that it does say that if you
[3156s] a halting halting states have to go to
[3158s] halting states and that's not terrible
[3162s] but in general this is not necessarily
[3164s] the right notion of morphism. It's
[3165s] actually very use. This actually does
[3168s] have a really uh this formalism does
[3170s] have a really good use case for uh
[3173s] understanding
[3174s] um uh uh systems with interfaces which
[3178s] we'll we'll probably come to but right
[3180s] now I'm going to say that these are
[3181s] known as co-alggebbras
[3185s] or f
[3191s] and uh
[3194s] maybe I should should leave it there and
[3196s] we've seen seen more kinds of systems.
[3198s] We've seen a bit more kind of
[3199s] representability. We've seen where the
[3202s] sort of quote unquote obvious Oh, well,
[3204s] I'm going to do one more. I'm going to
[3205s] do one more thing. We've seen where the
[3208s] the the obvious notion of map of system
[3210s] is is not necessarily the right notion
[3214s] with respect to representability. But
[3216s] let's also see how we could change that
[3218s] to get a very perfectly reasonable
[3221s] notion, a map, very categorical feeling,
[3224s] right? But nevertheless upgrades our
[3226s] representability. So now let's talk
[3228s] about like uh trajectories
[3232s] of discrete time
[3236s] and possibilistic systems.
[3242s] So again a possibilistic system sends
[3247s] every state to a set of future states.
[3250s] And so we'll say a trajectory here
[3255s] is a sequence
[3258s] sn
[3260s] uh you know
[3267s] uh so that well what we what we don't
[3270s] want to say that just sn + one equals
[3275s] equals the other one because the other
[3277s] one's a set and this is a single
[3278s] element. That was sort of a problem. But
[3279s] we want to say that it's a possible
[3281s] updated value
[3284s] in
[3286s] and then I will just immediately
[3288s] reformulate this by saying that SN plus1
[3291s] the singleton containing SN plus1 is
[3293s] contained in
[3300s] U of Sn.
[3303s] So now let's go back to our formulation
[3306s] here. We had Sn + one
[3310s] um uh well I I'll put it around
[3313s] singleton plus one to PN here.
[3319s] PN in other words uh I here or N maps to
[3324s] the singleton set containing n plus one.
[3327s] And then we'll have our sequence s here.
[3331s] We'll have our nondeterministic update
[3332s] here.
[3334s] And here we're going to have our P of S.
[3337s] And so if we look at where this part
[3340s] goes here,
[3342s] um it's going to go to the image of the
[3345s] singleton here. So this one is the
[3348s] singleton at SN plus one. Meanwhile,
[3351s] this N here goes to SN.
[3355s] And here we get the set USN. So again,
[3359s] this square is telling us the right
[3361s] things, but we don't want them to be
[3363s] equal. We want it a containment.
[3367s] So we want the containment to go this
[3368s] way.
[3371s] And this is what's known as a this is a
[3375s] a collax
[3377s] map
[3379s] of systems
[3382s] um in a from taking a term from higher
[3385s] category theory because here what we had
[3388s] to use is that the power set is not just
[3391s] a set anymore. It's actually an ordered
[3394s] set. It has this ordering of subsets.
[3397s] And if we keep in track of of that,
[3400s] there's an actual perfectly natural sort
[3402s] of uh sort of notion here. So um we we
[3406s] we can the the general setting for here
[3408s] is coax maps of co-algebbras
[3412s] of endofunctors on a two category.
[3416s] Um, I'm not going to go into that, but
[3417s] my point is that if you just try a
[3420s] little bit harder, you can often find
[3422s] that the right notion of map is just
[3424s] around the corner. Um, and we'll come
[3426s] back to this uh later uh and talk about
[3429s] how this notion of map allows us to
[3431s] represent not just trajectories of
[3433s] nondeterministic systems, but also uh
[3437s] things like leoponop functions.
